{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LCZ8OLmBOoK5FYw7TpI6jtx3x2OcDr42","timestamp":1679401072478},{"file_id":"1ivAoIspwJdZrrOFvp5ft2Hh0gzTn-gKC","timestamp":1678736398471}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Automated Speech Recognition\n","\n","The code does the following:\n","\n","*   Pulls the data in from github\n","*   Unzips the data\n","*   Creates Keras training and validation datasets\n","*   Extracts input-output data from the Keras datasets\n"],"metadata":{"id":"usc2kSY7fXMU"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"w_Nm-NM9c9Vq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679401213707,"user_tz":0,"elapsed":4243,"user":{"displayName":"Flavin Lee John","userId":"03778784406517451331"}},"outputId":"161b4091-7be0-464b-9b08-4ec5fade5422"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-21 12:20:11--  https://raw.githubusercontent.com/andrsn/data/main/speechImageData.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9872924 (9.4M) [application/zip]\n","Saving to: ‘speechImageData.zip’\n","\n","\rspeechImageData.zip   0%[                    ]       0  --.-KB/s               \rspeechImageData.zip 100%[===================>]   9.42M  --.-KB/s    in 0.04s   \n","\n","2023-03-21 12:20:12 (228 MB/s) - ‘speechImageData.zip’ saved [9872924/9872924]\n","\n"]}],"source":["# import libraries\n","import tensorflow as tf\n","\n","# get the data from github and unzip\n","!wget https://raw.githubusercontent.com/andrsn/data/main/speechImageData.zip\n","!unzip -q /content/speechImageData.zip\n"]},{"cell_type":"markdown","source":["## Pre-process data into training and validation sets, using Keras dataset objects\n","\n","Note that when the data is unzipped it is stored locally to Google Colab in the content folder and the unzipped folder is called \n","\n","'speechImageData - Copy'\n","\n","and it contains: \n","\n","the training data in the folder TrainData and \n","\n","the validation in the folder ValData\n","\n","There are 12 classes of different spoken words and the spectrograms, which form the input image data are of size 98x50 pixels."],"metadata":{"id":"Lji0v1zkvmCN"}},{"cell_type":"code","source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory='/content/speechImageData - Copy/TrainData', \n","    labels='inferred', \n","    color_mode=\"grayscale\", \n","    label_mode='categorical', \n","    batch_size=128, \n","    image_size=(98, 50)\n",")\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory='/content/speechImageData - Copy/ValData', \n","    labels='inferred', \n","    color_mode=\"grayscale\", \n","    label_mode='categorical', \n","    batch_size=128, \n","    image_size=(98, 50)\n",")"],"metadata":{"id":"FPTSYPMItpgG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679401414650,"user_tz":0,"elapsed":4087,"user":{"displayName":"Flavin Lee John","userId":"03778784406517451331"}},"outputId":"45d15d28-f144-4be2-c24b-3fb92aea875a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2001 files belonging to 12 classes.\n","Found 1171 files belonging to 12 classes.\n"]}]},{"cell_type":"markdown","source":["## Extract input-output data, which can be useful for plotting confusion matrices etc."],"metadata":{"id":"zsUT9haKa3p2"}},{"cell_type":"code","source":["# Extract the  training input images and output class labels\n","x_train = []\n","y_train = []\n","for images, labels in train_ds.take(-1):\n","    x_train.append(images.numpy())\n","    y_train.append(labels.numpy())\n","\n","x_train = tf.concat(x_train, axis=0)\n","y_train = tf.concat(y_train, axis=0)\n","\n","print(y_train)\n","\n","# Extract the validation input images and output class labels\n","x_val = []\n","y_val = []\n","for images, labels in val_ds.take(-1):\n","    x_val.append(images.numpy())\n","    y_val.append(labels.numpy())\n","\n","x_val = tf.concat(x_val, axis=0)\n","y_val = tf.concat(y_val, axis=0)\n","\n","print(y_val)\n","\n"],"metadata":{"id":"v22tCYk60i-9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679402521760,"user_tz":0,"elapsed":808,"user":{"displayName":"Flavin Lee John","userId":"03778784406517451331"}},"outputId":"d9804665-7d2d-422b-d456-f6a7accc054d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 1. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 1. 0. 0.]], shape=(2001, 12), dtype=float32)\n","tf.Tensor(\n","[[0. 0. 1. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]], shape=(1171, 12), dtype=float32)\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"i4ci_EG_REDs"}},{"cell_type":"markdown","source":["## Model Design"],"metadata":{"id":"-37zoAFERO2O"}},{"cell_type":"code","source":["\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix     \n","import seaborn as sns      \n","from keras.models import Sequential                               \n","from keras.layers import Dense, Dropout, BatchNormalization, Activation, Input, Conv2D, MaxPooling2D, Flatten, Softmax      \n","from keras import optimizers, regularizers "],"metadata":{"id":"gy4020Z2RCjs"},"execution_count":null,"outputs":[]}]}